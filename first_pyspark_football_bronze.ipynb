{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9975aedd-501d-42ad-b6cc-d28746036998",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create bronze layer database"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE DATABASE IF NOT EXISTS learning_catalog.football_bronze;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3bc8d3d-e0ce-4906-a488-e5ed0f425292",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is my first attempt using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e41361a-b636-4783-8e57-28a7210c2c66",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read a CSV with PySpark"
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Read file from Unity Catalog Volume \"/Volumes/learning_catalog/raw_data/landing\"\n",
    "raw_players_df = spark.read.format(\"csv\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .load(\"/Volumes/learning_catalog/raw_data/landing/players.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8369be9f-9e96-40db-b445-985cb39b3650",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Inspect the DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "raw_players_df.printSchema() # Show the inferred schema\n",
    "raw_players_df.show(5)      # Show the first 5 rows\n",
    "raw_players_df.count()      # Get the total number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc21987a-b4f7-4616-9e33-376c09a06949",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Write to Bronze Delta Table"
    }
   },
   "outputs": [],
   "source": [
    "# Define bronze table name\n",
    "bronze_table_name = \"learning_catalog.football_bronze.raw_players\" # Catalog.database.table\n",
    "\n",
    "# Write the PySpark df to a managed delta table\n",
    "raw_players_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(bronze_table_name)\n",
    "\n",
    "print(f\"Bronze table '{bronze_table_name}' created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "first_pyspark_football_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
